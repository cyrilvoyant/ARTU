\section{Introduction}
\label{sec:1}

Leveraging physics-based and statistical methods to explain and forecast time series has been playing an increasingly important role in energy meteorology \citep{article3,NOTTON201896}. It is logical to expect a rapid development of forecasting methods, in terms of both number and intricacy \citep{makridakis2021future}. In order to justify the choice of one method over another, forecast comparison is necessary. In that, superiority claims ought to be regarded as an essential component in all forecasting works. Under the ``publish or perish'' regime, overarching statements such as ``the proposed method outperforms the existing ones'' are ubiquitous and rapidly updated, which tend to result in a literature that is difficult to follow, to interpret, and to condense. Precautions must be taken. 

According to Wolpert's ``no free lunch'' theorem \citep{inbook1}, each time a predictive method is deemed superior in some aspects, there ought to be some other aspects in which the method does not perform as well comparing to its alternatives. In this regard, one may consider the classic example given by \citet{Gneiting2011}, in which two sets of forecasts optimized under different objectives (least squares and least absolute deviations) outperform each other under different evaluation metrics (root mean square error and mean absolute error); this is formally known as \textit{consistency in forecast verification} \citep{YANG202020}. In a more general sense, even when a simple method is compared to a sophisticated method, the former method has the advantage of being easy to implement, although its accuracy may not be as attractive as the latter. On this point, the problem of choosing a forecasting method, like many other problems of a similar nature, is one of balance. 

Another important aspect of forecast comparison is the situation under which the verification is conducted. In the field of renewable energy, in particular, intermittent solar energy, the optimality of a method depends on the geographical location, climate and weather regime, time-step, and forecast horizon; it does not make much sense to compare directly two sets of forecasts issued under distinct forecasting situations. Suppose some forecasts have been reported to be optimal in one forecasting situation, it may not compare favorably against its peers in another situation. Stated differently, knowing the optimal choice of method to be used in a particular situation is not straightforward, and one cannot simply take as true the conclusions made elsewhere. This is a limitation as to the general validity of inductive reasoning. In that, the only logical way to confirm that a method is indeed optimal is to test all existing methods for that given forecast situation.

This task is a necessarily difficult one. It is for that reason that, until now, there is no consensus on what constitutes a perfect model \citep{elke,FLIESS2018519,SOUBDHAN2016246}. Since enumerating and testing all existing methods is never quite possible, it is customary to leverage a na\"ive reference method during forecasting, such that forecasts made at different locations and over different time periods can be compared, though with appropriate caveats. Depending on the amount of improvement acquired, there would be different levels of enthusiasm for the methods of interest. 
In order for this approach to take effect, most generally, several prerequisites must be evaluated carefully. Firstly, reference methods should be applicable in various independent and operational modes \citep{DAVID2021672,en13143565,doi:10.1063/1.5114985,YANG2019410}. That is to say that the reference method should be ``universal'' in a sense that it does not depend on the type of available data. Secondly, the reference method must be sufficiently na\"ive, in that, it does not require dedicated knowledge to implement. For this reason, simple or very simple reference methods are preferred over elaborate reference methods that only provide slightly better results. Thirdly, when multiple na\"ive reference methods are present, the one with the highest accuracy should be used \citep{murphy_climatology_1992}. 

There are many reference methods in weather forecasting \citep{HONG2014357,9218967}. The most widely used ones are climatology and persistence \citep{YANG2019981} though the accuracy of these two references are generally low. Other time series reference methods are occasionally used, such as the simple exponential smoothing \citep{hyndman_forecasting_2018}. If we were to expand the list of reference methods in that direction, the choice becomes more flexible. In this paper, we propose to explore further options in order to effectively judge the quality of any new or existing forecasting methods in the solar radiation field. A new baseline approach is introduced to have a global indicator of the performance of all methods. 

The following pages are organized as follows. In Section \ref{sec:2}, various reference forecasting methods are introduced, which include four well-known methods, a newly proposed one, and a linear combination of the previous five. In Section \ref{sec:experiment}, the specifics related to the forecasting of climate and weather time series are underlined. In Section \ref{sec:result}, an application of these methods is firstly demonstrated on global horizontal irradiance (GHI) data measured in Ajaccio, France. Then, we check if the conclusions obtained for this site can be generalized for GHI series from four other sites with different climatological characteristics. The forecasting methods are applied to tilted global irradiance (TGI), which is more useful for solar photovoltaic applications, in view to verify the relevance of the methods. The final results refer to the temperature and wind time series in order to judge the portability of the methods we want to qualify as reference. Finally, Section \ref{sec:conclusion} is dedicated to conclusions.


