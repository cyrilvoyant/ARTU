\section{Conclusions}
\label{sec:conclusion}

In this paper, we proposed a new way of evaluating forecasts made in meteorology and more specifically in solar radiation (Statistical Reference Method i.e. SRM). As the current practice is to compare the results of elaborate forecasting methods with those of simple methods (naive or reference), it should be appreciated that simple methods can evolve and improve. In the solar world for example, the default reference model is to use persistence applied to the clear-sky index (sometimes also called smart persistence or scaled persistence). Recently, a new reference emerged from \cite{YANG2019981} that updated what was initially proposed by \cite{murphy_climatology_1992}. 

In this paper, we evaluated all reference methods (PER, CLIM, CLIPER and ES) under the same formalism based on putting forward the measurement error, seasonality and forecast error through covariance estimation. This resulted in an evolution of the technique and the proposition of a new, simple model that mixes prediction and filtration, which in the end is quite similar to an AR(2) with the additional quality that no learning process is necessary. We title this new method ARTU which is the main innovation of this work. 

Since forecasting features in many scientific fields,it is important to carefully examine the methodologies used in general and statistically. The statistical examination leads to multiple conclusions that should be used in subfields, such as solar radiation forecasting. This is the case of the benchmarks used in forecasting competitions as well as of naive methods. 

The use of the classical exponential smoothing (ES) tools has been demonstrated to be of use again. Though it has been used in some renewable energy papers \citep{DONG20131104}, it is not included as part of the references nor of the naive methods. However, we have shown in this paper that ES belongs in that category.

The choice to consider combination (COMB) as a reference method can be seen as an ``curiosity'', but in conclusion, when we combine two (or more) benchmarks it gives an improved benchmark that is still simple and meets the criteria of what can be considered a reference model. Averaging makes it possible to overcome outliers and smooth forecasts. After this study, we can recommend the use of the combination of simple models such as PER, CLIPER, ES and ARTU. Some rules have been put forward and the key recommendations of this study are:
\begin{itemize}[label=$\looparrowright$]  
\item Reference models are critical to justify any new forecasting approach;
\item The most appropriate benchmarking method depends on the nature of the variable being forecasted (seasonality, periodicity, forecastability) as well as the forecast horizon;
\item  The use of exponential smoothing for the estimation of ``regular" series (high forecastability) should not be overlooked;
\item The use of one error metrics specific to the time series forecasting community (MASE ) are real assets deserving of uptake in more applied fields like solar energy engineering;
\item The forecaster should endeavor to discover the benchmarking method the most appropriate for their setup by either using them all (PER, CLIPER, ES, ARTU and COMB) and taking the best approach or by justifying the selection.
\end{itemize}

The development of increasingly sophisticated forecasting methods is necessary, but it is crucial to be able to evaluate them and to benchmark their efforts against the expected results. There are some differences in the score values obtained (say, for nRMSE) among the benchmark approaches presented previously, though these are not fundamental. Since these are benchmarks, one can argue they exist to serve as a basis for comparison and so different reference models would not make much difference (since yielding close nRMSE values and behavior). This interpretation would be misleading because the gain observed with very complex methods or simpler methods is often of the order of a few percentage (or even less!). Therefore, it is important to offer the most efficient benchmark in order to be able to compare studies with each other and identify the most efficient models even if it comes down to a fine detail. It is important to mention that in the solar energy community, it is usual to consider that an improvement of 1\% in the prediction is approximately equivalent to an increase of 2\% in economical gain \citep{DAVID2021672}. For very large installations the gain can quickly become substantial.


 
